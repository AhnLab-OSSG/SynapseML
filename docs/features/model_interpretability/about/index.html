<!doctype html>
<html class="docs-version-0.9.1" lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.7">
<link rel="alternate" type="application/rss+xml" href="/SynapseML/blog/rss.xml" title="Synapse ML RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/SynapseML/blog/atom.xml" title="Synapse ML Atom Feed">
<link rel="search" type="application/opensearchdescription+xml" title="Synapse ML" href="/SynapseML/opensearch.xml"><title data-react-helmet="true">Model Interpretation on Spark | Synapse ML</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:image" content="https://microsoft.github.io/SynapseML/img/synapseml_og.jpg"><meta data-react-helmet="true" name="twitter:image" content="https://microsoft.github.io/SynapseML/img/synapseml_og.jpg"><meta data-react-helmet="true" property="og:url" content="https://microsoft.github.io/SynapseML/docs/features/model_interpretability/about/"><meta data-react-helmet="true" name="docsearch:language" content="en"><meta data-react-helmet="true" name="docsearch:version" content="0.9.1"><meta data-react-helmet="true" name="docsearch:docusaurus_tag" content="docs-default-0.9.1"><meta data-react-helmet="true" property="og:title" content="Model Interpretation on Spark | Synapse ML"><meta data-react-helmet="true" name="description" content="Interpretable Machine Learning"><meta data-react-helmet="true" property="og:description" content="Interpretable Machine Learning"><link data-react-helmet="true" rel="shortcut icon" href="/SynapseML/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://microsoft.github.io/SynapseML/docs/features/model_interpretability/about/"><link data-react-helmet="true" rel="alternate" href="https://microsoft.github.io/SynapseML/docs/features/model_interpretability/about/" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://microsoft.github.io/SynapseML/docs/features/model_interpretability/about/" hreflang="x-default"><link data-react-helmet="true" rel="preconnect" href="https://BH4D9OD16A-dsn.algolia.net" crossorigin="anonymous"><link rel="stylesheet" href="/SynapseML/assets/css/styles.99df1580.css">
<link rel="preload" href="/SynapseML/assets/js/runtime~main.95073f10.js" as="script">
<link rel="preload" href="/SynapseML/assets/js/main.00d7a27b.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"dark")}()</script><div id="__docusaurus">
<div><a href="#" class="skipToContent_1boX">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/SynapseML/"><div class="navbar__logo"><img src="/SynapseML/img/logo.svg" alt="SynapseML Logo" class="themedImage_3oOy themedImage--light_3ouy"><img src="/SynapseML/img/logo.svg" alt="SynapseML Logo" class="themedImage_3oOy themedImage--dark_3zJb"></div><b class="navbar__title">SynapseML</b></a><a class="navbar__item navbar__link" href="/SynapseML/docs/about/">Docs</a><a class="navbar__item navbar__link" href="/SynapseML/blog/">Blog</a><a class="navbar__item navbar__link" href="/SynapseML/videos/">Videos</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a class="navbar__link" href="/SynapseML/docs/about/">0.9.1</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/SynapseML/docs/next/features/model_interpretability/about/">Next</a></li><li><a aria-current="page" class="dropdown__link dropdown__link--active" href="/SynapseML/docs/features/model_interpretability/about/">0.9.1</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" class="navbar__link"><span><svg viewBox="0 0 20 20" width="20" height="20" aria-hidden="true" class="iconLanguage_tswG"><path fill="currentColor" d="M19.753 10.909c-.624-1.707-2.366-2.726-4.661-2.726-.09 0-.176.002-.262.006l-.016-2.063 3.525-.607c.115-.019.133-.119.109-.231-.023-.111-.167-.883-.188-.976-.027-.131-.102-.127-.207-.109-.104.018-3.25.461-3.25.461l-.013-2.078c-.001-.125-.069-.158-.194-.156l-1.025.016c-.105.002-.164.049-.162.148l.033 2.307s-3.061.527-3.144.543c-.084.014-.17.053-.151.143.019.09.19 1.094.208 1.172.018.08.072.129.188.107l2.924-.504.035 2.018c-1.077.281-1.801.824-2.256 1.303-.768.807-1.207 1.887-1.207 2.963 0 1.586.971 2.529 2.328 2.695 3.162.387 5.119-3.06 5.769-4.715 1.097 1.506.256 4.354-2.094 5.98-.043.029-.098.129-.033.207l.619.756c.08.096.206.059.256.023 2.51-1.73 3.661-4.515 2.869-6.683zm-7.386 3.188c-.966-.121-.944-.914-.944-1.453 0-.773.327-1.58.876-2.156a3.21 3.21 0 011.229-.799l.082 4.277a2.773 2.773 0 01-1.243.131zm2.427-.553l.046-4.109c.084-.004.166-.01.252-.01.773 0 1.494.145 1.885.361.391.217-1.023 2.713-2.183 3.758zm-8.95-7.668a.196.196 0 00-.196-.145h-1.95a.194.194 0 00-.194.144L.008 16.916c-.017.051-.011.076.062.076h1.733c.075 0 .099-.023.114-.072l1.008-3.318h3.496l1.008 3.318c.016.049.039.072.113.072h1.734c.072 0 .078-.025.062-.076-.014-.05-3.083-9.741-3.494-11.04zm-2.618 6.318l1.447-5.25 1.447 5.25H3.226z"></path></svg><span>English</span></span></a><ul class="dropdown__menu"><li><a href="/SynapseML/docs/features/model_interpretability/about/" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" style="text-transform:capitalize">English</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a class="navbar__link">Developer Docs</a><ul class="dropdown__menu"><li><a href="https://mmlspark.blob.core.windows.net/docs/0.9.1/pyspark/index.html" target="_blank" rel="noopener noreferrer" class="dropdown__link"><span>Python<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_37dV"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li><a href="https://mmlspark.blob.core.windows.net/docs/0.9.1/scala/com/microsoft/azure/synapse/ml/index.html" target="_blank" rel="noopener noreferrer" class="dropdown__link"><span>Scala<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_37dV"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><a href="https://github.com/microsoft/SynapseML" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="toggle_2iFN toggle_2ySP toggleChecked_XXXW toggleDisabled_1pbd"><div class="toggleTrack_1bVV" role="button" tabindex="-1"><div class="toggleTrackCheck_3GBG"><span class="toggleIcon_KBSf">ðŸŒœ</span></div><div class="toggleTrackX_1jae"><span class="toggleIcon_KBSf">ðŸŒž</span></div><div class="toggleTrackThumb_2_QT"></div></div><input type="checkbox" checked="" class="toggleScreenReader_32DE" aria-label="Switch between dark and light mode"></div><div class="searchBox_1Doo"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper docs-wrapper docs-doc-page"><div class="docPage_3zOJ"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_DkI0" type="button"></button><aside class="docSidebarContainer_G8MK"><div class="sidebar_1tWv"><nav class="menu thin-scrollbar menu_1Iah"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/SynapseML/docs/about/">Introduction</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#">Getting Started</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><a class="menu__link menu__link--sublist menu__link--active" href="#">Features</a><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/SynapseML/docs/features/CognitiveServices - Overview/">CognitiveServices - Overview</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#" tabindex="0">HTTP on Spark</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#" tabindex="0">LightGBM</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><a class="menu__link menu__link--sublist menu__link--active" href="#" tabindex="0">Model Interpretability</a><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/SynapseML/docs/features/model_interpretability/about/">About</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/SynapseML/docs/features/model_interpretability/ModelInterpretability - Snow Leopard Detection/">ModelInterpretability - Snow Leopard Detection</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#" tabindex="0">ONNX</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#" tabindex="0">Spark Serving</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#" tabindex="0">Vowpal Wabbit</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#">Examples</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#">Transformers</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#">Estimators</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#">Reference</a></li></ul></nav></div></aside><main class="docMainContainer_3Zec"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_2q91"><div class="docItemContainer_37q2"><article><span class="theme-doc-version-badge badge badge--secondary">Version: <!-- -->0.9.1</span><div class="tocCollapsible_3moT theme-doc-toc-mobile tocMobile_2bxg"><button type="button" class="clean-btn tocCollapsibleButton_3OYu">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Model Interpretation on Spark</h1></header><h2 class="anchor anchorWithStickyNavbar_1iPN" id="interpretable-machine-learning">Interpretable Machine Learning<a aria-hidden="true" class="hash-link" href="#interpretable-machine-learning" title="Direct link to heading">â€‹</a></h2><p>Interpretable Machine Learning helps developers, data scientists and business stakeholders in the organization gain a comprehensive understanding of their machine learning models. It can also be used to debug models, explain predictions and enable auditing to meet compliance with regulatory requirements.</p><h2 class="anchor anchorWithStickyNavbar_1iPN" id="why-run-model-interpretation-on-spark">Why run model interpretation on Spark<a aria-hidden="true" class="hash-link" href="#why-run-model-interpretation-on-spark" title="Direct link to heading">â€‹</a></h2><p>Model-agnostic interpretation methods can be computationally expensive due to the multiple evaluations needed to compute the explanations. Model interpretation on Spark enables users to interpret a black-box model at massive scales with the Apache Sparkâ„¢ distributed computing ecosystem. Various components support local interpretation for tabular, vector, image and text classification models, with two popular model-agnostic interpretation methods: <a href="https://arxiv.org/abs/1602.04938" target="_blank" rel="noopener noreferrer">LIME</a> and <a href="https://arxiv.org/abs/1705.07874" target="_blank" rel="noopener noreferrer">Kernel SHAP</a>.</p><h2 class="anchor anchorWithStickyNavbar_1iPN" id="usage">Usage<a aria-hidden="true" class="hash-link" href="#usage" title="Direct link to heading">â€‹</a></h2><p>Both LIME and Kernel SHAP are local interpretation methods. Local interpretation explains why does the model predict certain outcome for a given observation.</p><p>Both explainers extends from <code>org.apache.spark.ml.Transformer</code>. After setting up the explainer parameters, simply call the <code>transform</code> function on a <code>DataFrame</code> of observations to interpret the model behavior on these observations.</p><p>To see examples of model interpretability on Spark in action, take a look at these sample notebooks:</p><ul><li><a href="/SynapseML/docs/examples/model_interpretability/Interpretability - Tabular SHAP explainer/">Tabular SHAP explainer</a></li><li><a href="/SynapseML/docs/examples/model_interpretability/Interpretability - Image Explainers/">Image explainers</a></li><li><a href="/SynapseML/docs/examples/model_interpretability/Interpretability - Text Explainers/">Text explainers</a></li></ul><table><thead><tr><th></th><th>Tabular models</th><th>Vector models</th><th>Image models</th><th>Text models</th></tr></thead><tbody><tr><td>LIME explainers</td><td><a href="#tabularlime">TabularLIME</a></td><td><a href="#vectorlime">VectorLIME</a></td><td><a href="#imagelime">ImageLIME</a></td><td><a href="#textlime">TextLIME</a></td></tr><tr><td>Kernel SHAP explainers</td><td><a href="#tabularshap">TabularSHAP</a></td><td><a href="#vectorshap">VectorSHAP</a></td><td><a href="#imageshap">ImageSHAP</a></td><td><a href="#textshap">TextSHAP</a></td></tr></tbody></table><h3 class="anchor anchorWithStickyNavbar_1iPN" id="common-local-explainer-params">Common local explainer params<a aria-hidden="true" class="hash-link" href="#common-local-explainer-params" title="Direct link to heading">â€‹</a></h3><p>All local explainers support the following params:</p><table><thead><tr><th>Param</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td>targetCol</td><td><code>String</code></td><td>&quot;probability&quot;</td><td>The column name of the prediction target to explain (i.e. the response variable).  This is usually set to &quot;prediction&quot; for regression models and &quot;probability&quot; for probabilistic classification models.</td></tr><tr><td>targetClasses</td><td><code>Array[Int]</code></td><td>empty array</td><td>The indices of the classes for multinomial classification models.</td></tr><tr><td>targetClassesCol</td><td><code>String</code></td><td></td><td>The name of the column that specifies the indices of the classes for multinomial classification models.</td></tr><tr><td>outputCol</td><td><code>String</code></td><td></td><td>The name of the output column for interpretation results.</td></tr><tr><td>model</td><td><code>Transformer</code></td><td></td><td>The model to be explained.</td></tr></tbody></table><h3 class="anchor anchorWithStickyNavbar_1iPN" id="common-lime-explainer-params">Common LIME explainer params<a aria-hidden="true" class="hash-link" href="#common-lime-explainer-params" title="Direct link to heading">â€‹</a></h3><p>All LIME based explainers (<a href="#tabularlime">TabularLIME</a>, <a href="#vectorlime">VectorLIME</a>, <a href="#imagelime">ImageLIME</a>, <a href="#textlime">TextLIME</a>) support the following params:</p><table><thead><tr><th>Param</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td>regularization</td><td><code>Double</code></td><td>0</td><td>Regularization param for the underlying lasso regression.</td></tr><tr><td>kernelWidth</td><td><code>Double</code></td><td>sqrt(number of features) * 0.75</td><td>Kernel width for the exponential kernel.</td></tr><tr><td>numSamples</td><td><code>Int</code></td><td>1000</td><td>Number of samples to generate.</td></tr><tr><td>metricsCol</td><td><code>String</code></td><td>&quot;r2&quot;</td><td>Column name for fitting metrics.</td></tr></tbody></table><h3 class="anchor anchorWithStickyNavbar_1iPN" id="common-shap-explainer-params">Common SHAP explainer params<a aria-hidden="true" class="hash-link" href="#common-shap-explainer-params" title="Direct link to heading">â€‹</a></h3><p>All Kernel SHAP based explainers (<a href="#tabularshap">TabularSHAP</a>, <a href="#vectorshap">VectorSHAP</a>, <a href="#imageshap">ImageSHAP</a>, <a href="#textshap">TextSHAP</a>) support the following params:</p><table><thead><tr><th>Param</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td>infWeight</td><td><code>Double</code></td><td>1E8</td><td>The double value to represent infinite weight.</td></tr><tr><td>numSamples</td><td><code>Int</code></td><td>2 * (number of features) + 2048</td><td>Number of samples to generate.</td></tr><tr><td>metricsCol</td><td><code>String</code></td><td>&quot;r2&quot;</td><td>Column name for fitting metrics.</td></tr></tbody></table><h3 class="anchor anchorWithStickyNavbar_1iPN" id="tabular-model-explainer-params">Tabular model explainer params<a aria-hidden="true" class="hash-link" href="#tabular-model-explainer-params" title="Direct link to heading">â€‹</a></h3><p>All tabular model explainers (<a href="#tabularlime">TabularLIME</a>, <a href="#tabularshap">TabularSHAP</a>) support the following params:</p><table><thead><tr><th>Param</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td>inputCols</td><td><code>Array[String]</code></td><td></td><td>The names of input columns to the black-box model.</td></tr><tr><td>backgroundData</td><td><code>DataFrame</code></td><td></td><td>A dataframe containing background data. It must contain all the input columns needed by the black-box model.</td></tr></tbody></table><h3 class="anchor anchorWithStickyNavbar_1iPN" id="vector-model-explainer-params">Vector model explainer params<a aria-hidden="true" class="hash-link" href="#vector-model-explainer-params" title="Direct link to heading">â€‹</a></h3><p>All vector model explainers (<a href="#vectorlime">VectorLIME</a>, <a href="#vectorshap">VectorSHAP</a>) support the following params:</p><table><thead><tr><th>Param</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td>inputCol</td><td><code>String</code></td><td></td><td>The names of input vector column to the black-box model.</td></tr><tr><td>backgroundData</td><td><code>DataFrame</code></td><td></td><td>A dataframe containing background data. It must contain the input vector column needed by the black-box model.</td></tr></tbody></table><h3 class="anchor anchorWithStickyNavbar_1iPN" id="image-model-explainer-params">Image model explainer params<a aria-hidden="true" class="hash-link" href="#image-model-explainer-params" title="Direct link to heading">â€‹</a></h3><p>All image model explainers (<a href="#imagelime">ImageLIME</a>, <a href="#imageshap">ImageSHAP</a>) support the following params:</p><table><thead><tr><th>Param</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td>inputCol</td><td><code>String</code></td><td></td><td>The names of input image column to the black-box model.</td></tr><tr><td>cellSize</td><td><code>Double</code></td><td>16</td><td>Number that controls the size of the super-pixels.</td></tr><tr><td>modifier</td><td><code>Double</code></td><td>130</td><td>Controls the trade-off spatial and color distance of super-pixels.</td></tr><tr><td>superpixelCol</td><td><code>String</code></td><td>&quot;superpixels&quot;</td><td>The column holding the super-pixel decompositions.</td></tr></tbody></table><h3 class="anchor anchorWithStickyNavbar_1iPN" id="text-model-explainer-params">Text model explainer params<a aria-hidden="true" class="hash-link" href="#text-model-explainer-params" title="Direct link to heading">â€‹</a></h3><p>All text model explainers (<a href="#textlime">TextLIME</a>, <a href="#textshap">TextSHAP</a>) support the following params:</p><table><thead><tr><th>Param</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td>inputCol</td><td><code>String</code></td><td></td><td>The names of input text column to the black-box model.</td></tr><tr><td>tokensCol</td><td><code>String</code></td><td>&quot;tokens&quot;</td><td>The column holding the text tokens.</td></tr></tbody></table><h3 class="anchor anchorWithStickyNavbar_1iPN" id="tabularlime"><code>TabularLIME</code><a aria-hidden="true" class="hash-link" href="#tabularlime" title="Direct link to heading">â€‹</a></h3><table><thead><tr><th>Param</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td>categoricalFeatures</td><td><code>Array[String]</code></td><td>empty array</td><td>The name of columns that should be treated as categorical variables.</td></tr></tbody></table><blockquote><p>For categorical features, <code>TabularLIME</code> creates new samples by drawing samples based on the value distribution from the background dataset. For numerical features, it creates new samples by drawing from a normal distribution with mean taken from the target value to be explained, and standard deviation taken from the background dataset.</p></blockquote><h3 class="anchor anchorWithStickyNavbar_1iPN" id="tabularshap"><code>TabularSHAP</code><a aria-hidden="true" class="hash-link" href="#tabularshap" title="Direct link to heading">â€‹</a></h3><p>No additional params are supported.</p><h3 class="anchor anchorWithStickyNavbar_1iPN" id="vectorlime"><code>VectorLIME</code><a aria-hidden="true" class="hash-link" href="#vectorlime" title="Direct link to heading">â€‹</a></h3><p>No additional params are supported.</p><blockquote><p><code>VectorLIME</code> assumes all features are numerical, and categorical features are not supported in <code>VectorLIME</code>.</p></blockquote><h3 class="anchor anchorWithStickyNavbar_1iPN" id="vectorshap"><code>VectorSHAP</code><a aria-hidden="true" class="hash-link" href="#vectorshap" title="Direct link to heading">â€‹</a></h3><p>No additional params are supported.</p><h3 class="anchor anchorWithStickyNavbar_1iPN" id="imagelime"><code>ImageLIME</code><a aria-hidden="true" class="hash-link" href="#imagelime" title="Direct link to heading">â€‹</a></h3><table><thead><tr><th>Param</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td>samplingFraction</td><td><code>Double</code></td><td>0.7</td><td>The fraction of super-pixels to keep on during sampling.</td></tr></tbody></table><blockquote><p><code>ImageLIME</code> creates new samples by randomly turning super-pixels on or off with probability of keeping on set to <code>SamplingFraction</code>.</p></blockquote><h3 class="anchor anchorWithStickyNavbar_1iPN" id="imageshap"><code>ImageSHAP</code><a aria-hidden="true" class="hash-link" href="#imageshap" title="Direct link to heading">â€‹</a></h3><p>No additional params are supported.</p><h3 class="anchor anchorWithStickyNavbar_1iPN" id="textlime"><code>TextLIME</code><a aria-hidden="true" class="hash-link" href="#textlime" title="Direct link to heading">â€‹</a></h3><table><thead><tr><th>Param</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td>samplingFraction</td><td><code>Double</code></td><td>0.7</td><td>The fraction of word tokens to keep on during sampling.</td></tr></tbody></table><blockquote><p><code>TextLIME</code> creates new samples by randomly turning word tokens on or off with probability of keeping on set to <code>SamplingFraction</code>.</p></blockquote><h3 class="anchor anchorWithStickyNavbar_1iPN" id="textshap"><code>TextSHAP</code><a aria-hidden="true" class="hash-link" href="#textshap" title="Direct link to heading">â€‹</a></h3><p>No additional params are supported.</p><h2 class="anchor anchorWithStickyNavbar_1iPN" id="result-interpretation">Result interpretation<a aria-hidden="true" class="hash-link" href="#result-interpretation" title="Direct link to heading">â€‹</a></h2><h3 class="anchor anchorWithStickyNavbar_1iPN" id="lime-explainers">LIME explainers<a aria-hidden="true" class="hash-link" href="#lime-explainers" title="Direct link to heading">â€‹</a></h3><p>LIME explainers return an array of vectors, and each vector maps to a class being explained. Each component of the vector is the coefficient for the corresponding feature, super-pixel, or word token from the local surrogate model.</p><ul><li>For categorical variables, super-pixels, or word tokens, the coefficient shows the average change in model outcome if this feature is unknown to the model, if the super-pixel is replaced with background color (black), or if the word token is replaced with empty string.</li><li>For numeric variables, the coefficient shows the change in model outcome if the feature value is incremented by 1 unit.</li></ul><h3 class="anchor anchorWithStickyNavbar_1iPN" id="shap-explainers">SHAP explainers<a aria-hidden="true" class="hash-link" href="#shap-explainers" title="Direct link to heading">â€‹</a></h3><p>SHAP explainers return an array of vectors, and each vector maps to a class being explained. Each vector starts with the <a href="#base-value">base value</a>, and each following component of the vector is the Shapley value for each feature, super-pixel, or token.</p><p>The base value and Shapley values are additive, and they should add up to the model output for the target observation.</p><h4 class="anchor anchorWithStickyNavbar_1iPN" id="base-value">Base value<a aria-hidden="true" class="hash-link" href="#base-value" title="Direct link to heading">â€‹</a></h4><ul><li>For tabular and vector models, the base value represents the mean outcome of the model for the background dataset.</li><li>For image models, the base value represents the model outcome for a background (all black) image.</li><li>For text models, the base value represents the model outcome for an empty string.</li></ul></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/SynapseML/docs/features/lightgbm/LightGBM - Overview/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Â« <!-- -->LightGBM - Overview</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/SynapseML/docs/features/model_interpretability/ModelInterpretability - Snow Leopard Detection/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">ModelInterpretability - Snow Leopard Detection<!-- --> Â»</div></a></div></nav></div></div><div class="col col--3"><div class="tableOfContents_2pwG thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#interpretable-machine-learning" class="table-of-contents__link toc-highlight">Interpretable Machine Learning</a></li><li><a href="#why-run-model-interpretation-on-spark" class="table-of-contents__link toc-highlight">Why run model interpretation on Spark</a></li><li><a href="#usage" class="table-of-contents__link toc-highlight">Usage</a><ul><li><a href="#common-local-explainer-params" class="table-of-contents__link toc-highlight">Common local explainer params</a></li><li><a href="#common-lime-explainer-params" class="table-of-contents__link toc-highlight">Common LIME explainer params</a></li><li><a href="#common-shap-explainer-params" class="table-of-contents__link toc-highlight">Common SHAP explainer params</a></li><li><a href="#tabular-model-explainer-params" class="table-of-contents__link toc-highlight">Tabular model explainer params</a></li><li><a href="#vector-model-explainer-params" class="table-of-contents__link toc-highlight">Vector model explainer params</a></li><li><a href="#image-model-explainer-params" class="table-of-contents__link toc-highlight">Image model explainer params</a></li><li><a href="#text-model-explainer-params" class="table-of-contents__link toc-highlight">Text model explainer params</a></li><li><a href="#tabularlime" class="table-of-contents__link toc-highlight"><code>TabularLIME</code></a></li><li><a href="#tabularshap" class="table-of-contents__link toc-highlight"><code>TabularSHAP</code></a></li><li><a href="#vectorlime" class="table-of-contents__link toc-highlight"><code>VectorLIME</code></a></li><li><a href="#vectorshap" class="table-of-contents__link toc-highlight"><code>VectorSHAP</code></a></li><li><a href="#imagelime" class="table-of-contents__link toc-highlight"><code>ImageLIME</code></a></li><li><a href="#imageshap" class="table-of-contents__link toc-highlight"><code>ImageSHAP</code></a></li><li><a href="#textlime" class="table-of-contents__link toc-highlight"><code>TextLIME</code></a></li><li><a href="#textshap" class="table-of-contents__link toc-highlight"><code>TextSHAP</code></a></li></ul></li><li><a href="#result-interpretation" class="table-of-contents__link toc-highlight">Result interpretation</a><ul><li><a href="#lime-explainers" class="table-of-contents__link toc-highlight">LIME explainers</a></li><li><a href="#shap-explainers" class="table-of-contents__link toc-highlight">SHAP explainers</a></li></ul></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/SynapseML/docs/getting_started/installation/">Installation</a></li><li class="footer__item"><a class="footer__link-item" href="/SynapseML/docs/getting_started/first_example/">Getting Started</a></li><li class="footer__item"><a href="https://mmlspark.blob.core.windows.net/docs/0.9.1/pyspark/index.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Python API Reference</a></li><li class="footer__item"><a href="https://mmlspark.blob.core.windows.net/docs/0.9.1/scala/index.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Scala API Reference</a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/SynapseML/blog/">Blog</a></li><li class="footer__item"><a class="footer__link-item" href="/SynapseML/videos/">Videos</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items"><li class="footer__item"><a href="https://github.com/microsoft/SynapseML" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_37dV"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2021 Microsoft.</div></div></div></footer></div>
<script src="/SynapseML/assets/js/runtime~main.95073f10.js"></script>
<script src="/SynapseML/assets/js/main.00d7a27b.js"></script>
</body>
</html>