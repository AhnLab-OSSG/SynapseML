<!doctype html>
<html class="docs-version-current" lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.14">
<link rel="alternate" type="application/rss+xml" href="/SynapseML/blog/rss.xml" title="SynapseML RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/SynapseML/blog/atom.xml" title="SynapseML Atom Feed">
<link rel="alternate" type="application/json" href="/SynapseML/blog/feed.json" title="SynapseML JSON Feed">
<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-RWPE0183E8"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-RWPE0183E8",{anonymize_ip:!0})</script>
<link rel="search" type="application/opensearchdescription+xml" title="SynapseML" href="/SynapseML/opensearch.xml">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" integrity="sha384-Um5gpz1odJg5Z4HAmzPtgZKdTBHZdw8S29IecapCSB31ligYPhHQZMIlWLYQGVoc" crossorigin="anonymous"><title data-react-helmet="true">Model Interpretation on Spark | SynapseML</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:image" content="https://microsoft.github.io/SynapseML/img/synapseml_og.jpg"><meta data-react-helmet="true" name="twitter:image" content="https://microsoft.github.io/SynapseML/img/synapseml_og.jpg"><meta data-react-helmet="true" property="og:url" content="https://microsoft.github.io/SynapseML/docs/next/features/responsible_ai/Model Interpretation on Spark/"><meta data-react-helmet="true" name="docsearch:language" content="en"><meta data-react-helmet="true" name="docsearch:version" content="current"><meta data-react-helmet="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-react-helmet="true" property="og:title" content="Model Interpretation on Spark | SynapseML"><meta data-react-helmet="true" name="description" content="Interpretable Machine Learning"><meta data-react-helmet="true" property="og:description" content="Interpretable Machine Learning"><link data-react-helmet="true" rel="icon" href="/SynapseML/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://microsoft.github.io/SynapseML/docs/next/features/responsible_ai/Model Interpretation on Spark/"><link data-react-helmet="true" rel="alternate" href="https://microsoft.github.io/SynapseML/docs/next/features/responsible_ai/Model Interpretation on Spark/" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://microsoft.github.io/SynapseML/docs/next/features/responsible_ai/Model Interpretation on Spark/" hreflang="x-default"><link data-react-helmet="true" rel="preconnect" href="https://GBW8AA15RD-dsn.algolia.net" crossorigin="anonymous"><link rel="stylesheet" href="/SynapseML/assets/css/styles.074bcd8f.css">
<link rel="preload" href="/SynapseML/assets/js/runtime~main.97196f14.js" as="script">
<link rel="preload" href="/SynapseML/assets/js/main.45317aa7.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"dark")}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus">
<div><a href="#" class="skipToContent_1oUP">Skip to main content</a></div><div class="announcementBar_3WsW" role="banner"><div class="announcementBarPlaceholder_2m9F"></div><div class="announcementBarContent_3EUC">⭐️ If you like SynapseML, consider giving it a star on <a target="_blank" rel="noopener noreferrer" href="https://github.com/Microsoft/SynapseML">GitHub</a> ⭐</div><button type="button" class="clean-btn close announcementBarClose_38nx" aria-label="Close"><svg viewBox="0 0 15 15" width="14" height="14"><g stroke="currentColor" stroke-width="3.1"><path d="M.75.75l13.5 13.5M14.25.75L.75 14.25"></path></g></svg></button></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/SynapseML/"><div class="navbar__logo"><img src="/SynapseML/img/logo.svg" alt="SynapseML Logo" class="themedImage_1VuW themedImage--light_3UqQ"><img src="/SynapseML/img/logo.svg" alt="SynapseML Logo" class="themedImage_1VuW themedImage--dark_hz6m"></div><b class="navbar__title">SynapseML</b></a><a class="navbar__item navbar__link" href="/SynapseML/docs/about/">Docs</a><a class="navbar__item navbar__link" href="/SynapseML/blog/">Blog</a><a class="navbar__item navbar__link" href="/SynapseML/videos/">Videos</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a class="navbar__link" href="/SynapseML/docs/next/about/">Next</a><ul class="dropdown__menu"><li><a aria-current="page" class="dropdown__link dropdown__link--active" href="/SynapseML/docs/next/features/responsible_ai/Model Interpretation on Spark/">Next</a></li><li><a class="dropdown__link" href="/SynapseML/docs/features/responsible_ai/Model Interpretation on Spark/">0.9.5</a></li><li><a class="dropdown__link" href="/SynapseML/docs/0.9.4/features/responsible_ai/Model Interpretation on Spark/">0.9.4</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" class="navbar__link"><span><svg viewBox="0 0 20 20" width="20" height="20" aria-hidden="true" class="iconLanguage_3vod"><path fill="currentColor" d="M19.753 10.909c-.624-1.707-2.366-2.726-4.661-2.726-.09 0-.176.002-.262.006l-.016-2.063 3.525-.607c.115-.019.133-.119.109-.231-.023-.111-.167-.883-.188-.976-.027-.131-.102-.127-.207-.109-.104.018-3.25.461-3.25.461l-.013-2.078c-.001-.125-.069-.158-.194-.156l-1.025.016c-.105.002-.164.049-.162.148l.033 2.307s-3.061.527-3.144.543c-.084.014-.17.053-.151.143.019.09.19 1.094.208 1.172.018.08.072.129.188.107l2.924-.504.035 2.018c-1.077.281-1.801.824-2.256 1.303-.768.807-1.207 1.887-1.207 2.963 0 1.586.971 2.529 2.328 2.695 3.162.387 5.119-3.06 5.769-4.715 1.097 1.506.256 4.354-2.094 5.98-.043.029-.098.129-.033.207l.619.756c.08.096.206.059.256.023 2.51-1.73 3.661-4.515 2.869-6.683zm-7.386 3.188c-.966-.121-.944-.914-.944-1.453 0-.773.327-1.58.876-2.156a3.21 3.21 0 011.229-.799l.082 4.277a2.773 2.773 0 01-1.243.131zm2.427-.553l.046-4.109c.084-.004.166-.01.252-.01.773 0 1.494.145 1.885.361.391.217-1.023 2.713-2.183 3.758zm-8.95-7.668a.196.196 0 00-.196-.145h-1.95a.194.194 0 00-.194.144L.008 16.916c-.017.051-.011.076.062.076h1.733c.075 0 .099-.023.114-.072l1.008-3.318h3.496l1.008 3.318c.016.049.039.072.113.072h1.734c.072 0 .078-.025.062-.076-.014-.05-3.083-9.741-3.494-11.04zm-2.618 6.318l1.447-5.25 1.447 5.25H3.226z"></path></svg><span>English</span></span></a><ul class="dropdown__menu"><li><a href="/SynapseML/docs/next/features/responsible_ai/Model Interpretation on Spark/" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active">English</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" class="navbar__link">Developer Docs</a><ul class="dropdown__menu"><li><a href="https://mmlspark.blob.core.windows.net/docs/0.9.5/pyspark/index.html" target="_blank" rel="noopener noreferrer" class="dropdown__link"><span>Python<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li><a href="https://mmlspark.blob.core.windows.net/docs/0.9.5/scala/com/microsoft/azure/synapse/ml/index.html" target="_blank" rel="noopener noreferrer" class="dropdown__link"><span>Scala<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><a href="https://github.com/microsoft/SynapseML" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="toggle_71bT toggle_3Zt9 toggleChecked_2FvV toggleDisabled_3cF-"><div class="toggleTrack_32Fl" role="button" tabindex="-1"><div class="toggleTrackCheck_3lV7"><span class="toggleIcon_O4iE">🌜</span></div><div class="toggleTrackX_S2yS"><span class="toggleIcon_O4iE">🌞</span></div><div class="toggleTrackThumb_xI_Z"></div></div><input type="checkbox" checked="" class="toggleScreenReader_28Tw" aria-label="Switch between dark and light mode"></div><div class="searchBox_1Kl_"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper docs-wrapper docs-doc-page"><div class="docPage_31aa"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_35hR" type="button"></button><aside class="docSidebarContainer_3Kbt"><div class="sidebar_15mo"><nav class="menu thin-scrollbar menu_Bmed menuWithAnnouncementBar_2WvA"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/SynapseML/docs/next/about/">Introduction</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_2fq0" href="/SynapseML/docs/next/getting_started/installation/">Getting Started</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active hasHref_2fq0" href="/SynapseML/docs/next/features/cognitive_services/CognitiveServices - Analyze Text/">Features</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_2fq0" tabindex="0" href="/SynapseML/docs/next/features/cognitive_services/CognitiveServices - Analyze Text/">Cognitive Services</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_2fq0" tabindex="0" href="/SynapseML/docs/next/features/isolation_forest/IsolationForest - Multivariate Anomaly Detection/">Isolation Forest</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_2fq0" tabindex="0" href="/SynapseML/docs/next/features/geospatial_services/GeospatialServices - Flooding Risk/">Geospatial Services</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active hasHref_2fq0" tabindex="0" href="/SynapseML/docs/next/features/responsible_ai/Data Balance Analysis/">Responsible AI</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/SynapseML/docs/next/features/responsible_ai/Data Balance Analysis/">Data Balance Analysis</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/SynapseML/docs/next/features/responsible_ai/DataBalanceAnalysis - Adult Census Income/">DataBalanceAnalysis - Adult Census Income</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/SynapseML/docs/next/features/responsible_ai/Interpretability - Explanation Dashboard/">Interpretability - Explanation Dashboard</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/SynapseML/docs/next/features/responsible_ai/Interpretability - Image Explainers/">Interpretability - Image Explainers</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/SynapseML/docs/next/features/responsible_ai/Interpretability - PDP and ICE explainer/">Interpretability - PDP and ICE explainer</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/SynapseML/docs/next/features/responsible_ai/Interpretability - Snow Leopard Detection/">Interpretability - Snow Leopard Detection</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/SynapseML/docs/next/features/responsible_ai/Interpretability - Tabular SHAP explainer/">Interpretability - Tabular SHAP explainer</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/SynapseML/docs/next/features/responsible_ai/Interpretability - Text Explainers/">Interpretability - Text Explainers</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/SynapseML/docs/next/features/responsible_ai/Model Interpretation on Spark/">Model Interpretation on Spark</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_2fq0" tabindex="0" href="/SynapseML/docs/next/features/onnx/ONNX - Inference on Spark/">ONNX</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_2fq0" tabindex="0" href="/SynapseML/docs/next/features/lightgbm/LightGBM - Overview/">LightGBM</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_2fq0" tabindex="0" href="/SynapseML/docs/next/features/vw/Vowpal Wabbit - Overview/">Vowpal Wabbit</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_2fq0" tabindex="0" href="/SynapseML/docs/next/features/spark_serving/SparkServing - Deploying a Classifier/">Spark Serving</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_2fq0" tabindex="0" href="/SynapseML/docs/next/features/opencv/OpenCV - Pipeline Image Transformations/">OpenCV</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_2fq0" tabindex="0" href="/SynapseML/docs/next/features/classification/Classification - Adult Census with Vowpal Wabbit/">Classification</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_2fq0" tabindex="0" href="/SynapseML/docs/next/features/regression/Regression - Auto Imports/">Regression</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_2fq0" tabindex="0" href="/SynapseML/docs/next/features/other/AzureSearchIndex - Met Artworks/">Other</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_2fq0" href="/SynapseML/docs/next/documentation/transformers/transformers_cognitive/">Transformers</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_2fq0" href="/SynapseML/docs/next/documentation/estimators/estimators_cognitive/">Estimators</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_2fq0" href="/SynapseML/docs/next/mlflow/introduction/">MLflow</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_2fq0" href="/SynapseML/docs/next/reference/developer-readme/">Reference</a></div></li></ul></nav></div></aside><main class="docMainContainer_3ufF"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_3FnS"><div class="theme-doc-version-banner alert alert--warning margin-bottom--md" role="alert"><div>This is unreleased documentation for <!-- -->SynapseML<!-- --> <b>Next</b> version.</div><div class="margin-top--md">For up-to-date documentation, see the <b><a href="/SynapseML/docs/features/responsible_ai/Model Interpretation on Spark/">latest version</a></b> (<!-- -->0.9.5<!-- -->).</div></div><div class="docItemContainer_33ec"><article><span class="theme-doc-version-badge badge badge--secondary">Version: <!-- -->Next</span><div class="tocCollapsible_1PrD theme-doc-toc-mobile tocMobile_3Hoh"><button type="button" class="clean-btn tocCollapsibleButton_2O1e">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Model Interpretation on Spark</h1></header><h2 class="anchor anchorWithStickyNavbar_31ik" id="interpretable-machine-learning">Interpretable Machine Learning<a class="hash-link" href="#interpretable-machine-learning" title="Direct link to heading">​</a></h2><p>Interpretable Machine Learning helps developers, data scientists and business stakeholders in the organization gain a comprehensive understanding of their machine learning models. It can also be used to debug models, explain predictions and enable auditing to meet compliance with regulatory requirements.</p><h2 class="anchor anchorWithStickyNavbar_31ik" id="why-run-model-interpretation-on-spark">Why run model interpretation on Spark<a class="hash-link" href="#why-run-model-interpretation-on-spark" title="Direct link to heading">​</a></h2><p>Model-agnostic interpretation methods can be computationally expensive due to the multiple evaluations needed to compute the explanations. Model interpretation on Spark enables users to interpret a black-box model at massive scales with the Apache Spark™ distributed computing ecosystem. Various components support local interpretation for tabular, vector, image and text classification models, with two popular model-agnostic interpretation methods: <a href="https://arxiv.org/abs/1602.04938" target="_blank" rel="noopener noreferrer">LIME</a> and <a href="https://arxiv.org/abs/1705.07874" target="_blank" rel="noopener noreferrer">Kernel SHAP</a>.</p><h2 class="anchor anchorWithStickyNavbar_31ik" id="usage">Usage<a class="hash-link" href="#usage" title="Direct link to heading">​</a></h2><p>Both LIME and Kernel SHAP are local interpretation methods. Local interpretation explains why does the model predict certain outcome for a given observation.</p><p>Both explainers extends from <code>org.apache.spark.ml.Transformer</code>. After setting up the explainer parameters, simply call the <code>transform</code> function on a <code>DataFrame</code> of observations to interpret the model behavior on these observations.</p><p>To see examples of model interpretability on Spark in action, take a look at these sample notebooks:</p><ul><li><a href="/SynapseML/docs/next/features/responsible_ai/Interpretability - Tabular SHAP explainer/">Tabular SHAP explainer</a></li><li><a href="/SynapseML/docs/next/features/responsible_ai/Interpretability - Image Explainers/">Image explainers</a></li><li><a href="/SynapseML/docs/next/features/responsible_ai/Interpretability - Text Explainers/">Text explainers</a></li></ul><table><thead><tr><th></th><th>Tabular models</th><th>Vector models</th><th>Image models</th><th>Text models</th></tr></thead><tbody><tr><td>LIME explainers</td><td><a href="#tabularlime">TabularLIME</a></td><td><a href="#vectorlime">VectorLIME</a></td><td><a href="#imagelime">ImageLIME</a></td><td><a href="#textlime">TextLIME</a></td></tr><tr><td>Kernel SHAP explainers</td><td><a href="#tabularshap">TabularSHAP</a></td><td><a href="#vectorshap">VectorSHAP</a></td><td><a href="#imageshap">ImageSHAP</a></td><td><a href="#textshap">TextSHAP</a></td></tr></tbody></table><h3 class="anchor anchorWithStickyNavbar_31ik" id="common-local-explainer-params">Common local explainer params<a class="hash-link" href="#common-local-explainer-params" title="Direct link to heading">​</a></h3><p>All local explainers support the following params:</p><table><thead><tr><th>Param</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td>targetCol</td><td><code>String</code></td><td>&quot;probability&quot;</td><td>The column name of the prediction target to explain (i.e. the response variable).  This is usually set to &quot;prediction&quot; for regression models and &quot;probability&quot; for probabilistic classification models.</td></tr><tr><td>targetClasses</td><td><code>Array[Int]</code></td><td>empty array</td><td>The indices of the classes for multinomial classification models.</td></tr><tr><td>targetClassesCol</td><td><code>String</code></td><td></td><td>The name of the column that specifies the indices of the classes for multinomial classification models.</td></tr><tr><td>outputCol</td><td><code>String</code></td><td></td><td>The name of the output column for interpretation results.</td></tr><tr><td>model</td><td><code>Transformer</code></td><td></td><td>The model to be explained.</td></tr></tbody></table><h3 class="anchor anchorWithStickyNavbar_31ik" id="common-lime-explainer-params">Common LIME explainer params<a class="hash-link" href="#common-lime-explainer-params" title="Direct link to heading">​</a></h3><p>All LIME based explainers (<a href="#tabularlime">TabularLIME</a>, <a href="#vectorlime">VectorLIME</a>, <a href="#imagelime">ImageLIME</a>, <a href="#textlime">TextLIME</a>) support the following params:</p><table><thead><tr><th>Param</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td>regularization</td><td><code>Double</code></td><td>0</td><td>Regularization param for the underlying lasso regression.</td></tr><tr><td>kernelWidth</td><td><code>Double</code></td><td>sqrt(number of features) * 0.75</td><td>Kernel width for the exponential kernel.</td></tr><tr><td>numSamples</td><td><code>Int</code></td><td>1000</td><td>Number of samples to generate.</td></tr><tr><td>metricsCol</td><td><code>String</code></td><td>&quot;r2&quot;</td><td>Column name for fitting metrics.</td></tr></tbody></table><h3 class="anchor anchorWithStickyNavbar_31ik" id="common-shap-explainer-params">Common SHAP explainer params<a class="hash-link" href="#common-shap-explainer-params" title="Direct link to heading">​</a></h3><p>All Kernel SHAP based explainers (<a href="#tabularshap">TabularSHAP</a>, <a href="#vectorshap">VectorSHAP</a>, <a href="#imageshap">ImageSHAP</a>, <a href="#textshap">TextSHAP</a>) support the following params:</p><table><thead><tr><th>Param</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td>infWeight</td><td><code>Double</code></td><td>1E8</td><td>The double value to represent infinite weight.</td></tr><tr><td>numSamples</td><td><code>Int</code></td><td>2 * (number of features) + 2048</td><td>Number of samples to generate.</td></tr><tr><td>metricsCol</td><td><code>String</code></td><td>&quot;r2&quot;</td><td>Column name for fitting metrics.</td></tr></tbody></table><h3 class="anchor anchorWithStickyNavbar_31ik" id="tabular-model-explainer-params">Tabular model explainer params<a class="hash-link" href="#tabular-model-explainer-params" title="Direct link to heading">​</a></h3><p>All tabular model explainers (<a href="#tabularlime">TabularLIME</a>, <a href="#tabularshap">TabularSHAP</a>) support the following params:</p><table><thead><tr><th>Param</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td>inputCols</td><td><code>Array[String]</code></td><td></td><td>The names of input columns to the black-box model.</td></tr><tr><td>backgroundData</td><td><code>DataFrame</code></td><td></td><td>A dataframe containing background data. It must contain all the input columns needed by the black-box model.</td></tr></tbody></table><h3 class="anchor anchorWithStickyNavbar_31ik" id="vector-model-explainer-params">Vector model explainer params<a class="hash-link" href="#vector-model-explainer-params" title="Direct link to heading">​</a></h3><p>All vector model explainers (<a href="#vectorlime">VectorLIME</a>, <a href="#vectorshap">VectorSHAP</a>) support the following params:</p><table><thead><tr><th>Param</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td>inputCol</td><td><code>String</code></td><td></td><td>The names of input vector column to the black-box model.</td></tr><tr><td>backgroundData</td><td><code>DataFrame</code></td><td></td><td>A dataframe containing background data. It must contain the input vector column needed by the black-box model.</td></tr></tbody></table><h3 class="anchor anchorWithStickyNavbar_31ik" id="image-model-explainer-params">Image model explainer params<a class="hash-link" href="#image-model-explainer-params" title="Direct link to heading">​</a></h3><p>All image model explainers (<a href="#imagelime">ImageLIME</a>, <a href="#imageshap">ImageSHAP</a>) support the following params:</p><table><thead><tr><th>Param</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td>inputCol</td><td><code>String</code></td><td></td><td>The names of input image column to the black-box model.</td></tr><tr><td>cellSize</td><td><code>Double</code></td><td>16</td><td>Number that controls the size of the super-pixels.</td></tr><tr><td>modifier</td><td><code>Double</code></td><td>130</td><td>Controls the trade-off spatial and color distance of super-pixels.</td></tr><tr><td>superpixelCol</td><td><code>String</code></td><td>&quot;superpixels&quot;</td><td>The column holding the super-pixel decompositions.</td></tr></tbody></table><h3 class="anchor anchorWithStickyNavbar_31ik" id="text-model-explainer-params">Text model explainer params<a class="hash-link" href="#text-model-explainer-params" title="Direct link to heading">​</a></h3><p>All text model explainers (<a href="#textlime">TextLIME</a>, <a href="#textshap">TextSHAP</a>) support the following params:</p><table><thead><tr><th>Param</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td>inputCol</td><td><code>String</code></td><td></td><td>The names of input text column to the black-box model.</td></tr><tr><td>tokensCol</td><td><code>String</code></td><td>&quot;tokens&quot;</td><td>The column holding the text tokens.</td></tr></tbody></table><h3 class="anchor anchorWithStickyNavbar_31ik" id="tabularlime"><code>TabularLIME</code><a class="hash-link" href="#tabularlime" title="Direct link to heading">​</a></h3><table><thead><tr><th>Param</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td>categoricalFeatures</td><td><code>Array[String]</code></td><td>empty array</td><td>The name of columns that should be treated as categorical variables.</td></tr></tbody></table><blockquote><p>For categorical features, <code>TabularLIME</code> creates new samples by drawing samples based on the value distribution from the background dataset. For numerical features, it creates new samples by drawing from a normal distribution with mean taken from the target value to be explained, and standard deviation taken from the background dataset.</p></blockquote><h3 class="anchor anchorWithStickyNavbar_31ik" id="tabularshap"><code>TabularSHAP</code><a class="hash-link" href="#tabularshap" title="Direct link to heading">​</a></h3><p>No additional params are supported.</p><h3 class="anchor anchorWithStickyNavbar_31ik" id="vectorlime"><code>VectorLIME</code><a class="hash-link" href="#vectorlime" title="Direct link to heading">​</a></h3><p>No additional params are supported.</p><blockquote><p><code>VectorLIME</code> assumes all features are numerical, and categorical features are not supported in <code>VectorLIME</code>.</p></blockquote><h3 class="anchor anchorWithStickyNavbar_31ik" id="vectorshap"><code>VectorSHAP</code><a class="hash-link" href="#vectorshap" title="Direct link to heading">​</a></h3><p>No additional params are supported.</p><h3 class="anchor anchorWithStickyNavbar_31ik" id="imagelime"><code>ImageLIME</code><a class="hash-link" href="#imagelime" title="Direct link to heading">​</a></h3><table><thead><tr><th>Param</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td>samplingFraction</td><td><code>Double</code></td><td>0.7</td><td>The fraction of super-pixels to keep on during sampling.</td></tr></tbody></table><blockquote><p><code>ImageLIME</code> creates new samples by randomly turning super-pixels on or off with probability of keeping on set to <code>SamplingFraction</code>.</p></blockquote><h3 class="anchor anchorWithStickyNavbar_31ik" id="imageshap"><code>ImageSHAP</code><a class="hash-link" href="#imageshap" title="Direct link to heading">​</a></h3><p>No additional params are supported.</p><h3 class="anchor anchorWithStickyNavbar_31ik" id="textlime"><code>TextLIME</code><a class="hash-link" href="#textlime" title="Direct link to heading">​</a></h3><table><thead><tr><th>Param</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td>samplingFraction</td><td><code>Double</code></td><td>0.7</td><td>The fraction of word tokens to keep on during sampling.</td></tr></tbody></table><blockquote><p><code>TextLIME</code> creates new samples by randomly turning word tokens on or off with probability of keeping on set to <code>SamplingFraction</code>.</p></blockquote><h3 class="anchor anchorWithStickyNavbar_31ik" id="textshap"><code>TextSHAP</code><a class="hash-link" href="#textshap" title="Direct link to heading">​</a></h3><p>No additional params are supported.</p><h2 class="anchor anchorWithStickyNavbar_31ik" id="result-interpretation">Result interpretation<a class="hash-link" href="#result-interpretation" title="Direct link to heading">​</a></h2><h3 class="anchor anchorWithStickyNavbar_31ik" id="lime-explainers">LIME explainers<a class="hash-link" href="#lime-explainers" title="Direct link to heading">​</a></h3><p>LIME explainers return an array of vectors, and each vector maps to a class being explained. Each component of the vector is the coefficient for the corresponding feature, super-pixel, or word token from the local surrogate model.</p><ul><li>For categorical variables, super-pixels, or word tokens, the coefficient shows the average change in model outcome if this feature is unknown to the model, if the super-pixel is replaced with background color (black), or if the word token is replaced with empty string.</li><li>For numeric variables, the coefficient shows the change in model outcome if the feature value is incremented by 1 unit.</li></ul><h3 class="anchor anchorWithStickyNavbar_31ik" id="shap-explainers">SHAP explainers<a class="hash-link" href="#shap-explainers" title="Direct link to heading">​</a></h3><p>SHAP explainers return an array of vectors, and each vector maps to a class being explained. Each vector starts with the <a href="#base-value">base value</a>, and each following component of the vector is the Shapley value for each feature, super-pixel, or token.</p><p>The base value and Shapley values are additive, and they should add up to the model output for the target observation.</p><h4 class="anchor anchorWithStickyNavbar_31ik" id="base-value">Base value<a class="hash-link" href="#base-value" title="Direct link to heading">​</a></h4><ul><li>For tabular and vector models, the base value represents the mean outcome of the model for the background dataset.</li><li>For image models, the base value represents the model outcome for a background (all black) image.</li><li>For text models, the base value represents the model outcome for an empty string.</li></ul></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/SynapseML/docs/next/features/responsible_ai/Interpretability - Text Explainers/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Interpretability - Text Explainers</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/SynapseML/docs/next/features/onnx/ONNX - Inference on Spark/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">ONNX - Inference on Spark</div></a></div></nav></div></div><div class="col col--3"><div class="tableOfContents_35-E thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#interpretable-machine-learning" class="table-of-contents__link toc-highlight">Interpretable Machine Learning</a></li><li><a href="#why-run-model-interpretation-on-spark" class="table-of-contents__link toc-highlight">Why run model interpretation on Spark</a></li><li><a href="#usage" class="table-of-contents__link toc-highlight">Usage</a><ul><li><a href="#common-local-explainer-params" class="table-of-contents__link toc-highlight">Common local explainer params</a></li><li><a href="#common-lime-explainer-params" class="table-of-contents__link toc-highlight">Common LIME explainer params</a></li><li><a href="#common-shap-explainer-params" class="table-of-contents__link toc-highlight">Common SHAP explainer params</a></li><li><a href="#tabular-model-explainer-params" class="table-of-contents__link toc-highlight">Tabular model explainer params</a></li><li><a href="#vector-model-explainer-params" class="table-of-contents__link toc-highlight">Vector model explainer params</a></li><li><a href="#image-model-explainer-params" class="table-of-contents__link toc-highlight">Image model explainer params</a></li><li><a href="#text-model-explainer-params" class="table-of-contents__link toc-highlight">Text model explainer params</a></li><li><a href="#tabularlime" class="table-of-contents__link toc-highlight"><code>TabularLIME</code></a></li><li><a href="#tabularshap" class="table-of-contents__link toc-highlight"><code>TabularSHAP</code></a></li><li><a href="#vectorlime" class="table-of-contents__link toc-highlight"><code>VectorLIME</code></a></li><li><a href="#vectorshap" class="table-of-contents__link toc-highlight"><code>VectorSHAP</code></a></li><li><a href="#imagelime" class="table-of-contents__link toc-highlight"><code>ImageLIME</code></a></li><li><a href="#imageshap" class="table-of-contents__link toc-highlight"><code>ImageSHAP</code></a></li><li><a href="#textlime" class="table-of-contents__link toc-highlight"><code>TextLIME</code></a></li><li><a href="#textshap" class="table-of-contents__link toc-highlight"><code>TextSHAP</code></a></li></ul></li><li><a href="#result-interpretation" class="table-of-contents__link toc-highlight">Result interpretation</a><ul><li><a href="#lime-explainers" class="table-of-contents__link toc-highlight">LIME explainers</a></li><li><a href="#shap-explainers" class="table-of-contents__link toc-highlight">SHAP explainers</a></li></ul></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/SynapseML/docs/getting_started/installation/">Installation</a></li><li class="footer__item"><a class="footer__link-item" href="/SynapseML/docs/getting_started/first_example/">Getting Started</a></li><li class="footer__item"><a href="https://mmlspark.blob.core.windows.net/docs/0.9.5/pyspark/index.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Python API Reference</a></li><li class="footer__item"><a href="https://mmlspark.blob.core.windows.net/docs/0.9.5/scala/index.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Scala API Reference</a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/SynapseML/blog/">Blog</a></li><li class="footer__item"><a class="footer__link-item" href="/SynapseML/videos/">Videos</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items"><li class="footer__item"><a href="https://github.com/microsoft/SynapseML" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2022 Microsoft.</div></div></div></footer></div>
<script src="/SynapseML/assets/js/runtime~main.97196f14.js"></script>
<script src="/SynapseML/assets/js/main.45317aa7.js"></script>
</body>
</html>